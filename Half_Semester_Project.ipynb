{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodingTask1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xMCTH/DSFMCTH/blob/main/Half_Semester_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Science Fundamentals for DCBP, S. Haug, University of Bern "
      ],
      "metadata": {
        "id": "_-1mhuoK6uqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Answer background questions, and upload them to your github\n",
        "\n",
        "1. Which packages are available for ML? Describe the pros and cons and document the availability.\n",
        "\n",
        "- TensorFlow: TensorFlow is a platform for building and training machine learning models, but it requires a certain level of expertise to use effectively. Its flexibility and scalability make it a popular choice for large-scale machine learning applications, but its complexity and computationally-intensive nature can make it challenging for beginners or those with limited computational resources.\n",
        "- Scikit-learn: Scikit-learn is a widely used machine learning library that provides many tools and algorithms for building and evaluating machine learning models. While it may not provide the latest cutting-edge techniques in machine learning and may not be suitable for all types of datasets and machine learning problems, its simplicity, ease-of-use, and integration with other popular Python libraries make it a great choice for many machine learning applications.\n",
        "- theano:Theano is a flexible library for building and training machine learning models. Its support for automatic differentiation and GPU computation make it a great choice for large-scale machine learning applications. However, it may be less accessible to beginners and may require more coding and configuration than other libraries. Additionally, Theano's lack of recent development may make it less attractive compared to other libraries with more active development.\n",
        "- Keras: Keras is a easy-to-use library for building and training deep learning models. Its high-level API and pre-built model architectures make it a great choice for beginners or those who need to quickly prototype deep learning models. However, it may not provide the same level of flexibility and control as other deep learning libraries, and may not be the best choice for all types of deep learning applications.\n",
        "- nlp: NLP is a versatile field of machine learning that can help organizations gain insights from human language data. However, it also has some limitations and challenges, such as computational complexity and bias, that must be addressed. As with any machine learning technique, it is important to carefully consider the strengths and limitations of NLP and to use it appropriately for specific tasks and applications.\n",
        "- PyTorch:  PyTorch is a easy-to-use library for building and training deep learning models. Its dynamic computation graph and ease of use make it a great choice for beginners or those who need to quickly prototype deep learning models. However, it may not be as optimized for large-scale distributed computing, and may require more manual configuration or code for certain operations or workflows.\n",
        "- seaborn: Seaborn is a data visualization library that can be a great tool for machine learning applications. While it may not be suitable for all types of visualizations and may require some additional knowledge to use effectively, its built-in statistical visualizations and ease-of-use make it a popular choice for many data scientists and machine learning practitioners.\n",
        "\n",
        "2. What is Chembl? How do you access it?\n",
        "\n",
        "- ChEMBL is a publicly available database of bioactive molecules with drug-like properties, and their associated targets, including information on bioactivity, pharmacology, and ADMET (absorption, distribution, metabolism, excretion, and toxicity) properties. It is maintained by the European Bioinformatics Institute (EBI) and provides valuable resources for drug discovery research.\n",
        "- ChEMBL can be accessed through the website https://www.ebi.ac.uk/chembl/ where molecules or targets can be searched. It is also accessed through ChEMBL Python client library, which allows programmatic access to the data for automated analysis and integration into workflows.\n",
        "\n",
        "3. What is machine learning, and how does it differ from traditional programming?\n",
        "\n",
        "- Machine learning is a subset of artificial intelligence that involves the development of algorithms and statistical models that enable computers to learn and make predictions or decisions based on data, without being explicitly programmed to do so.\n",
        "\n",
        "- The main difference between traditional programming and machine learning is that in traditional programming, the programmer explicitly specifies the rules and instructions for the computer to follow, whereas in machine learning, the computer learns from data and builds its own set of rules or models to make predictions or decisions. This is often referred to as \"data-driven\" or \"inductive\" programming.\n",
        "\n",
        "4. What are the key concepts and techniques in machine learning?\n",
        "\n",
        "- Neural Networks: This is a type of machine learning that is based on the structure and function of the human brain. Neural networks are composed of interconnected nodes that process and transmit information.\n",
        "- Deep Learning: This is a type of neural network that is capable of learning from large amounts of data. Deep learning models typically have many layers and can learn to represent complex relationships in the data.\n",
        "- Feature Engineering: This is the process of selecting and transforming the input data to improve the performance of a machine learning model. Feature engineering involves selecting relevant variables, encoding categorical variables, and normalizing the data.\n",
        "- Cross-Validation: This is a technique used to evaluate the performance of a machine learning model. Cross-validation involves splitting the data into training and validation sets, and then evaluating the model on the validation set.\n",
        "- Hyperparameter Tuning: This is the process of selecting the optimal values for the hyperparameters of a machine learning model. Hyperparameters are parameters that are set prior to training the model, such as the learning rate, number of hidden layers, and regularization strength.\n",
        "- Evaluation Metrics: These are measures used to evaluate the performance of a machine learning model. Examples include accuracy, precision, recall, F1-score, and ROC-AUC.\n",
        "\n",
        "5. What are the different types of machine learning algorithms?\n",
        "\n",
        "- Supervised Learning Algorithms: These are algorithms that learn from labeled data. They are called \"supervised\" because the training data includes both input variables (features) and output variables (labels or targets). The goal of a supervised learning algorithm is to learn a function that maps the input variables to the output variables. Examples of supervised learning algorithms include linear regression, logistic regression, decision trees, random forests, and support vector machines.\n",
        "\n",
        "- Unsupervised Learning Algorithms: These are algorithms that learn from unlabeled data. They are called \"unsupervised\" because the training data only includes input variables (features) and does not include output variables (labels or targets). The goal of an unsupervised learning algorithm is to find patterns or structures in the data, such as clusters or groups of similar data points. Examples of unsupervised learning algorithms include k-means clustering, hierarchical clustering, principal component analysis (PCA), and t-distributed stochastic neighbor embedding (t-SNE).\n",
        "\n",
        "-     Reinforcement Learning Algorithms: These are algorithms that learn by interacting with an environment and receiving feedback in the form of rewards or penalties. The goal of a reinforcement learning algorithm is to learn a policy or strategy that maximizes the expected reward over time. Reinforcement learning algorithms are commonly used in robotics, game playing, and autonomous systems. Examples of reinforcement learning algorithms include Q-learning, policy gradient methods, and deep reinforcement learning.\n",
        "\n",
        "6. What are the common applications of machine learning?\n",
        "\n",
        "- Machine learning helps software applications become even more accurate at predicting outcomes without being explicitly programmed.\n",
        "\n",
        "- Web search and ranking pages based on search preferences.\n",
        "- Evaluating risk in finance on credit offers and knowing where is best to invest.â€¯\n",
        "- Predicting customer churn in e-commerce.\n",
        "- Space exploration and sending probes to space.\n",
        "- The advance in robotics and autonomous, self-driving cars.\n",
        "- Extracting data on relationships and preferences from social media.\n",
        "- Speeding up the debugging process in computer science.\n",
        "- Image and Speech Recognition\n",
        "- Fraud Detection\n",
        "- Healthcare: Machine learning algorithms can be used to analyze medical data, predict diseases, and personalize treatment plans\n",
        "\n",
        "7. How do you evaluate the performance of a machine learning model?\n",
        "\n",
        "- Accuracy: This measures how often the model correctly predicts the outcome. It is calculated by dividing the number of correct predictions by the total number of predictions.\n",
        "\n",
        "- Precision: This measures the proportion of true positives (correctly identified instances) among all the positive predictions. It is calculated by dividing the number of true positives by the sum of true positives and false positives.\n",
        "\n",
        "- Recall: This measures the proportion of true positives that were correctly identified by the model among all actual positives. It is calculated by dividing the number of true positives by the sum of true positives and false negatives.\n",
        "\n",
        "- F1 Score: This is the harmonic mean of precision and recall, and provides a balance between the two metrics.\n",
        "\n",
        "- Confusion Matrix: This is a table that shows the number of correct and incorrect predictions made by the model, and is useful for evaluating the model's performance across different classes.\n",
        "\n",
        "- Receiver Operating Characteristic (ROC) Curve: This is a plot of the true positive rate (sensitivity) against the false positive rate (1 - specificity) at various threshold settings, and is useful for evaluating the performance of a binary classification model.\n",
        "\n",
        "- Mean Squared Error (MSE): This is a metric used for regression problems that measures the average squared difference between the predicted and actual values.\n",
        "\n",
        "8. How do you prepare data for use in a machine learning model?\n",
        "\n",
        "- Data Transformation: Converting the data into a format suitable for machine learning models. This may include converting categorical variables into numerical values, scaling the data to ensure that all variables have equal weight, and applying feature engineering techniques to create new features from existing data.\n",
        "\n",
        "- Exploratory Data Analysis: Data professionals use statistical parameters like mean, median, mode, standard deviations, etc., and graphical representations. Analyzing data helps identify missing values, outliers, and inconsistencies among variables. It also gives a fair idea of how the values of each variable are distributed across the space.\n",
        "\n",
        "- Data Cleaning: Identifying and dealing with missing values, outliers, and inconsistencies in the data. Missing values can be replaced with mean, median, or mode values, or using imputation techniques such as K-Nearest Neighbors (KNN). Outliers can be removed or replaced with a more appropriate value. Inconsistencies can be corrected by manually inspecting the data or using data profiling tools.\n",
        "\n",
        "- Feature Selection: Selecting the most relevant features that are useful for the model. This can be done using statistical tests, feature importance scores, or domain knowledge.\n",
        "\n",
        "- Feature Engineering:  Used for variables (for example colour of flower) in your dataset that can be converted into useful features using encoding methods.\n",
        "\n",
        "Additional answers and code for the midthermproject are in the repository of my group partner, which is linked in the ReadMe file\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gn4RkUC66-ou"
      }
    }
  ]
}